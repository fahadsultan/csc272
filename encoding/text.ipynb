{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text is arguably the most ubiquitous non-numeric modality of data. Most of the data on the internet is text. Text data generally exists as a **collection of documents** called **corpus**, where each document is one or more **sentences**.  \n",
    "\n",
    "### Bag of Words\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/fahadsultan/csc272/main/assets/bow.png\" width=\"90%\" style=\"filter:invert(1)\"/></center>\n",
    "\n",
    "Text data can be encoded into a number of different numeric representations. The most common is the **Bag-of-Words** (BoW) representation, which is closely related with One-Hot Encoding. \n",
    "\n",
    "In the BoW representation, **each row represents a document** and **each column represents a word** in the vocabulary.  The **vocabulary** is the list of all unique words in the corpus. The corpus is the collection of all the documents. A document is a sequence of words. **The value in the cell at $i$th row and $j$th column represents the number of times the word $j$ appears in  document $i$**. \n",
    "\n",
    "Creating a Bag of Words representation for a corpus generally entails the following steps:\n",
    "\n",
    "1. **Tokenization**: Split each document into a sequence of tokens (words).\n",
    "2. Create **Vocabulary**: Create a list of all unique tokens (words) for all documents in the corpus. Often words are normalized by converting all words to lowercase and removing punctuation.\n",
    "3. Create **Document Vectors**: Create a vector for each document in the corpus. The vector is the same length as the vocabulary. The value in each cell of the vector is the number of times the word in the corresponding column appears in the document.\n",
    "4. Create **Document-Term Matrix**: Create a 2D array where each row represents a document and each column represents a word in the vocabulary. The value in the cell at $i$th row and $j$th column represents the number of times the word $j$ appears in  document $i$.\n",
    "\n",
    "The image below shows a bag-of-words representation of a corpus of two documents. The vocabulary is the list of words on the left. The corpus is the 2D array of numbers on the right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really enjoyed the movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The food was terrible</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not sure how I feel about this</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The service was excellent</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had a bad experience</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              message sentiment\n",
       "0          I really enjoyed the movie  positive\n",
       "1               The food was terrible  negative\n",
       "2  I'm not sure how I feel about this   neutral\n",
       "3           The service was excellent  positive\n",
       "4              I had a bad experience  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/fahadsultan/csc272/main/data/chat_dataset.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>really</th>\n",
       "      <th>enjoyed</th>\n",
       "      <th>the</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>food</th>\n",
       "      <th>was</th>\n",
       "      <th>terrible</th>\n",
       "      <th>i'm</th>\n",
       "      <th>...</th>\n",
       "      <th>ex</th>\n",
       "      <th>is</th>\n",
       "      <th>dating</th>\n",
       "      <th>someone</th>\n",
       "      <th>new.</th>\n",
       "      <th>i</th>\n",
       "      <th>feel</th>\n",
       "      <th>so</th>\n",
       "      <th>heartbroken</th>\n",
       "      <th>ðŸ’”ðŸ˜¢</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  really  enjoyed  the  movie  the  food  was  terrible  i'm  ...  ex  is  \\\n",
       "0  1       1        1    1      1    1     0    0         0    0  ...   0   0   \n",
       "1  1       0        0    0      0    0     1    1         1    0  ...   0   0   \n",
       "2  1       0        0    0      0    0     0    0         0    0  ...   0   1   \n",
       "3  1       0        0    0      0    0     0    1         0    0  ...   1   0   \n",
       "4  1       0        0    0      0    0     0    0         0    0  ...   1   0   \n",
       "\n",
       "   dating  someone  new.  i  feel  so  heartbroken  ðŸ’”ðŸ˜¢  \n",
       "0       0        0     0  1     0   0            0   0  \n",
       "1       0        0     0  1     0   0            0   0  \n",
       "2       0        0     0  1     1   0            0   0  \n",
       "3       0        0     0  1     0   0            0   0  \n",
       "4       0        0     0  1     0   0            0   0  \n",
       "\n",
       "[5 rows x 4291 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Tokenization: Concatenate all messages into a single string and convert to lowercase and then split into words\n",
    "tokens = (' '.join(data['message'].values)).lower().split()\n",
    "\n",
    "# 2. Vocabulary: Create a list of UNIQUE words in the dataset\n",
    "vocab = list(set(tokens))\n",
    "\n",
    "# 4. Create an empty DataFrame with columns as the words in the vocab\n",
    "bow = pd.DataFrame(columns=vocab)\n",
    "\n",
    "# Go through each word in the vocab\n",
    "for word in vocab: \n",
    "\n",
    "    # 3. For each message, count the number of times the word appears\n",
    "    bow[word] = data['message'].apply(lambda msg: msg.count(word))\n",
    "\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "In practice, the Bag-of-Words representation is created using libraries such as `scikit-learn`. \n",
    "\n",
    "The `CountVectorizer` class in `scikit-learn` can be used to create a Bag-of-Words representation of a corpus.\n",
    "\n",
    "In the code below, we create a corpus of two documents. We then create an instance of the `CountVectorizer` class and use it to fit and transform the corpus into a Bag-of-Words representation. The resulting Bag-of-Words representation is a sparse matrix, which we convert to a dense array using the `toarray()` method. Finally, we print the vocabulary and the Bag-of-Words representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  first  is  second  the  this\n",
       "0         1      1   1       0    1     1\n",
       "1         2      0   1       1    1     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.'\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus to create the bag-of-words representation\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the result to a DataFrame for better visualization\n",
    "X = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that count vectorizer automatically converts all words to lowercase and removes punctuation.\n",
    "\n",
    "It is also more efficient than creating the Bag-of-Words representation manually, as it uses sparse matrices to store the data. Sparse matrices only store the non-zero values, which saves memory and computation time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
